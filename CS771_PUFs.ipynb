{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78879c7e-4f8b-433a-ae6e-88f7b2150be8",
      "metadata": {
        "id": "78879c7e-4f8b-433a-ae6e-88f7b2150be8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression  # <-- CRITICAL LINE\n",
        "from scipy.linalg import khatri_rao\n",
        "from sklearn.svm import LinearSVC\n",
        "import time as tm\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1d148e-7776-4aee-b12f-fc80ffdf4f71",
      "metadata": {
        "id": "5a1d148e-7776-4aee-b12f-fc80ffdf4f71"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'],\n",
        "    'max_iter': [1000, 2500, 5000]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ac496e-a843-4188-882c-ca0d8002b85e",
      "metadata": {
        "id": "88ac496e-a843-4188-882c-ca0d8002b85e"
      },
      "outputs": [],
      "source": [
        "def my_fit( X_train, y_train ):\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\n",
        "\t# Use this method to train your models using training CRPs\n",
        "\t# X_train has 8 columns containing the challenge bits\n",
        "\t# y_train contains the values for responses\n",
        "\n",
        "\t# THE RETURNED MODEL SHOULD BE ONE VECTOR AND ONE BIAS TERM\n",
        "\t# If you do not wish to use a bias term, set it to 0\n",
        "\t# return w, b\n",
        "    # Map the challenges to the ML-PUF feature space\n",
        "    X_feat = my_map(X_train)\n",
        "\n",
        "    # Use GridSearchCV for optimal hyperparameter selection\n",
        "    #param_grid = {\n",
        "       #'C': [0.001, 0.01, 0.1, 1, 10],              # Regularization strength\n",
        "        #'penalty': ['l2'],                           # Regularization type\n",
        "        #'solver': ['liblinear', 'lbfgs'],           # Algorithm to use\n",
        "        #'max_iter': [1000, 2000],                   # Maximum iterations\n",
        "        #'tol': [1e-4, 1e-5]                         # Convergence tolerance\n",
        "    #}\n",
        "\n",
        "    clf = LogisticRegression(\n",
        "        C=0.1,                # Optimal regularization strength\n",
        "        penalty='l2',         # L2 regularization (Ridge)\n",
        "        solver='lbfgs',       # Limited-memory BFGS algorithm\n",
        "        max_iter=1000,        # Sufficient iterations for convergence\n",
        "        tol=0.0001,           # Optimal tolerance for convergence\n",
        "        random_state=42       # For reproducibility\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    clf.fit(X_feat, y_train)\n",
        "\n",
        "    # Return model weights and bias in required format\n",
        "    return clf.coef_.reshape(-1), clf.intercept_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dcfdca6-cb1a-42ba-b7e1-2eed7dbccc0f",
      "metadata": {
        "id": "4dcfdca6-cb1a-42ba-b7e1-2eed7dbccc0f"
      },
      "outputs": [],
      "source": [
        "def my_map( X ):\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\n",
        "\t# Use this method to create features.\n",
        "\t# It is likely that my_fit will internally call my_map to create features for train points\n",
        "\t# return feat\n",
        "    X_pm = 2 * X - 1\n",
        "    phi = np.cumprod(np.flip(X_pm, axis=1), axis=1)\n",
        "\n",
        "    # Create indices for main diagonal and 2 off-diagonals using list comprehension\n",
        "    diag_indices = [(i, j) for i in range(8) for j in range(i, min(i+3, 8))]\n",
        "\n",
        "    # Convert list of tuples to two arrays for row and column indices\n",
        "    row_idx, col_idx = zip(*diag_indices)\n",
        "\n",
        "    # Use broadcasting to compute all features at once\n",
        "    features = phi[:, row_idx] * phi[:, col_idx]\n",
        "\n",
        "    # Apply scaling for faster convergence\n",
        "    features_scaled = features / np.sqrt(np.mean(features**2, axis=1, keepdims=True) + 1e-10)\n",
        "\n",
        "    return features_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac8adff-5ef1-4930-9c35-a82041fe63da",
      "metadata": {
        "id": "7ac8adff-5ef1-4930-9c35-a82041fe63da"
      },
      "outputs": [],
      "source": [
        "def my_decode( w ):\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\n",
        "\t# Use this method to invert a PUF linear model to get back delays\n",
        "\t# w is a single 65-dim vector (last dimension being the bias term)\n",
        "\t# The output should be four 64-dimensional vectors\n",
        "\t# -*- coding: utf-8 -*-\n",
        "\"\"\"submit.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/18THH5wSVHLaF_oOO_HXdMy61NpoeiULr\n",
        "\"\"\"\n",
        "    \"\"\"\n",
        "    Takes a 65-dimensional linear model w as input and returns four\n",
        "    64-dimensional non-negative delay vectors: p, q, r, s\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure w is a 1D array\n",
        "    w = np.asarray(w).flatten()\n",
        "\n",
        "    # Separate out the bias term\n",
        "    w_bias = w[-1]\n",
        "    w_main = w[:-1]  # This is of shape (64,)\n",
        "\n",
        "    # Initialize delay vectors\n",
        "    alpha = np.copy(w_main)\n",
        "    beta = np.copy(w_main)\n",
        "\n",
        "    # Following the relation:\n",
        "    # w = alpha + beta (excluding last element)\n",
        "    # and w = alpha - beta (shifted version)\n",
        "\n",
        "    # Solve for alpha and beta using equations:\n",
        "    # alpha = (w[i] + w[i+1]) / 2\n",
        "    # beta  = (w[i] - w[i+1]) / 2\n",
        "    alpha = (w_main + np.roll(w_main, -1)) / 2\n",
        "    beta = (w_main - np.roll(w_main, -1)) / 2\n",
        "\n",
        "    # Remove the wrap-around artifact in last value\n",
        "    alpha[-1] = w_main[-1] / 2\n",
        "    beta[-1] = w_main[-1] / 2\n",
        "\n",
        "    # Construct p, q, r, s from alpha and beta\n",
        "    p = np.maximum(alpha, 0)\n",
        "    q = np.maximum(-alpha, 0)\n",
        "    r = np.maximum(beta, 0)\n",
        "    s = np.maximum(-beta, 0)\n",
        "\n",
        "    return p, q, r, s\n",
        "\t# return p, q, r, s\n",
        "    return np.zeros(64), np.zeros(64), np.zeros(64), np.zeros(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5840d1a8-1b7a-4b7e-9e60-7f903ae42dd7",
      "metadata": {
        "id": "5840d1a8-1b7a-4b7e-9e60-7f903ae42dd7"
      },
      "outputs": [],
      "source": [
        "Z_trn = np.loadtxt( \"/Users/ashutoshanand/Downloads/mp1/public_trn.txt\" )\n",
        "Z_tst = np.loadtxt( \"/Users/ashutoshanand/Downloads/mp1/public_tst.txt\" )\n",
        "\n",
        "n_trials = 5\n",
        "\n",
        "d_size = 0\n",
        "t_train = 0\n",
        "t_map = 0\n",
        "acc = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ff6916-17ce-4a44-9dba-9d9a290044f6",
      "metadata": {
        "id": "73ff6916-17ce-4a44-9dba-9d9a290044f6"
      },
      "outputs": [],
      "source": [
        "for t in range( n_trials ):\n",
        "  tic = tm.perf_counter()\n",
        "  w, b = my_fit( Z_trn[:, :-1], Z_trn[:,-1] )\n",
        "  toc = tm.perf_counter()\n",
        "\n",
        "  t_train += toc - tic\n",
        "  w = w.reshape( -1 )\n",
        "\n",
        "  d_size += w.shape[0]\n",
        "\n",
        "  tic = tm.perf_counter()\n",
        "  feat = my_map( Z_tst[:, :-1] )\n",
        "  toc = tm.perf_counter()\n",
        "  t_map += toc - tic\n",
        "\n",
        "  scores = feat.dot( w ) + b\n",
        "\n",
        "  pred = np.zeros_like( scores )\n",
        "  pred[ scores > 0 ] = 1\n",
        "\n",
        "  acc += np.average( Z_tst[ :, -1 ] == pred )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c332500-f5d8-4ef9-b5da-bcd50c125bc3",
      "metadata": {
        "id": "6c332500-f5d8-4ef9-b5da-bcd50c125bc3"
      },
      "outputs": [],
      "source": [
        "d_size /= n_trials\n",
        "t_train /= n_trials\n",
        "t_map /= n_trials\n",
        "acc /= n_trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "151d5d58-eaac-41ba-ab2c-ff3947cc18a9",
      "metadata": {
        "id": "151d5d58-eaac-41ba-ab2c-ff3947cc18a9"
      },
      "outputs": [],
      "source": [
        "def get_model( p, q, r, s ):\n",
        "  p = np.maximum( p, 0 )\n",
        "  q = np.maximum( q, 0 )\n",
        "  r = np.maximum( r, 0 )\n",
        "  s = np.maximum( s, 0 )\n",
        "  d = p - q\n",
        "  c = r - s\n",
        "  alpha = ( d + c ) / 2\n",
        "  beta = ( d - c ) / 2\n",
        "  w = np.zeros( ( len( alpha ) + 1, )  )\n",
        "  w[:-1] += alpha\n",
        "  w[1:] += beta\n",
        "  return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08eebe98-f956-4965-a0c5-4d3ea73996f8",
      "metadata": {
        "scrolled": true,
        "id": "08eebe98-f956-4965-a0c5-4d3ea73996f8"
      },
      "outputs": [],
      "source": [
        "W = np.loadtxt( \"/Users/ashutoshanand/Downloads/mp1/public_mod.txt\" )\n",
        "( n_models, dims ) = W.shape\n",
        "t_decode = 0\n",
        "m_dist = 0\n",
        "for t in range( n_trials ):\n",
        "  for itr in range( n_models ):\n",
        "    w = W[ itr, : ]\n",
        "    tic = tm.perf_counter()\n",
        "    p_hat, q_hat, r_hat, s_hat = my_decode( w )\n",
        "    toc = tm.perf_counter()\n",
        "    t_decode += toc - tic\n",
        "    w_hat = get_model( p_hat, q_hat, r_hat, s_hat )\n",
        "    m_dist += np.linalg.norm( w - w_hat )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffe69cef-05ab-4c13-94f6-9cb0265e2c8f",
      "metadata": {
        "id": "ffe69cef-05ab-4c13-94f6-9cb0265e2c8f"
      },
      "outputs": [],
      "source": [
        "t_decode /= ( n_trials * n_models )\n",
        "m_dist /= ( n_trials * n_models )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8e8e50-b44f-47a7-a113-a7f4bc8d86c3",
      "metadata": {
        "id": "3c8e8e50-b44f-47a7-a113-a7f4bc8d86c3",
        "outputId": "d0333d0c-2434-4956-9798-3da6b23ac2fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21.0,0.023665116727352144,0.0024788502138108014,0.31375,5.726693198084831e-06,1.6199987057689555\n"
          ]
        }
      ],
      "source": [
        "print( f\"{d_size},{t_train},{t_map},{1 - acc},{t_decode},{m_dist}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00060ead-d3da-4511-8ab7-6ba8cddb320b",
      "metadata": {
        "id": "00060ead-d3da-4511-8ab7-6ba8cddb320b",
        "outputId": "b2910355-a534-4380-e69b-d142dde20fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21.0,0.013124933373183012,0.0006810663733631372,0.318125,2.7591409161686897e-06,1.6199987057689555\n"
          ]
        }
      ],
      "source": [
        "print( f\"{d_size},{t_train},{t_map},{1 - acc},{t_decode},{m_dist}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc9e31fb-0cfa-456a-a610-23284dae534d",
      "metadata": {
        "id": "bc9e31fb-0cfa-456a-a610-23284dae534d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:anaconda3] *",
      "language": "python",
      "name": "conda-env-anaconda3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}